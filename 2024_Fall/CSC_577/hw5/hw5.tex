%
% Latex comments start with the percent symbol.
%
% This file should create a pdf on a mac or Linux command line by running:
%     pdflatex hw1.tex
% I usually add a few options
%     pdflatex -halt-on-error -interaction=nonstopmode -file-line-error hw1.tex
% 
% If you are new to Latex, you might not know that you may need to run the above
% twice for the compiler to sort out its references. (There are ways to finesse
% this). 
%

\documentclass[12pt]{report}

% Whether or not you need all these packages, or even some more will vary. These
% are some common ones, but not all are needed for this document. There is no
% real harm loading your favorites out of habit. 


\usepackage[fleqn]{amsmath}%amsmath,
\usepackage{algorithm,algorithmic,alltt,amssymb,bm,
    cancel,color,fullpage,graphicx,listings,mathrsfs,
    multirow,subcaption,upgreek,xcolor}
\usepackage[numbered,framed]{matlab-prettifier}
\usepackage[colorlinks]{hyperref}
\usepackage[nameinlink,noabbrev]{cleveref}
\usepackage[verbose]{placeins}
\usepackage{caption}
\usepackage[skip=0.1ex, belowskip=1ex,
            labelformat=brace,
            singlelinecheck=off]{subcaption}
\usepackage[nodisplayskipstretch]{setspace}
% \setstretch{1.5}
\usepackage[left=2cm,right=2cm,top=2cm,bottom=2cm]{geometry}

\doublespacing

%%%%%%%%%%%%%%%%%%%%%%%%%%%% Operators %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Your personal shortcuts. You do not need to use any. argmax and argmin
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}

%% Distributions
\newcommand{\N}{\mathcal{N}}
\newcommand{\U}{\mathcal{U}}
\newcommand{\Poi}{{\text Poisson}}
\newcommand{\Exp}{{\text Exp}}
\newcommand{\G}{\mathcal{G}}
\newcommand{\Ber}{{\text Bern}}
\newcommand{\Lap}{{\text Laplace}}
\newcommand{\btheta}{\boldsymbol{\theta}}
\newcommand{\bSigma}{\boldsymbol{\Sigma}}
% Code blocks formatting

\definecolor{MyDarkGreen}{rgb}{0.0,0.4,0.0}

% For faster processing, load Matlab syntax for listings
\lstloadlanguages{Matlab}%
\lstset{language=Matlab,        % Use MATLAB
        % frame=single,   % Single frame around code
        basicstyle=\small\ttfamily,     % Use small true type font
        keywordstyle=[1]\color{blue}\bfseries,  % MATLAB functions bold and blue
        keywordstyle=[2]\color{purple}, % MATLAB function arguments purple
        keywordstyle=[3]\color{blue}\underbar,  % User functions underlined and blue
        identifierstyle=,       % Nothing special about identifiers
        % Comments small dark green courier
        commentstyle=\usefont{T1}{pcr}{m}{sl}\color{MyDarkGreen}\small,
        stringstyle=\color{purple},     % Strings are purple
        showstringspaces=false,         % Don't put marks in string spaces
        tabsize=2,      % 2 spaces per tab
        %%% Put standard MATLAB functions not included in the default language here
        morekeywords={xlim,ylim,var,alpha,factorial,poissrnd,normpdf,normcdf},
        %%% Put MATLAB function parameters here
        morekeywords=[2]{on, off, interp},
        %%% Put user defined functions here
        morekeywords=[3]{hw1,hw2,},
        gobble=4,
        morecomment=[l][\color{blue}]{...},     % Line continuation (...) like blue comment
        numbers=left,   % Line numbers on left
        firstnumber=1,          % Line numbers start with line 1
        numberstyle=\tiny\color{blue},  % Line numbers are blue
        stepnumber=5    % Line numbers go in steps of 5
}

%% Probability
\newcommand{\E}[1]{\mathbb{E}[#1]}
\newcommand{\Cov}[2]{\mathbb{C}\mathrm{ov}(#1,#2)}

%% Bold font for vectors from Ernesto, but I do not know how the first one
%  works, but it seems necessary for the second?
\def\*#1{\mathbf{#1}}
\newcommand*{\V}[1]{\mathbf{#1}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}


\centerline{\it CS 577}
\centerline{\it HW \#5 Submission}
\centerline{\it Name: Joses Omojola}

Questions from Part A-C were completed in matlab and saved in the \emph{hw5.m} program. The program creates an \emph{output} folder to save images, 
so that the root directory is not always cluttered. The program can be run using \textit{hw5()}, and the results to coding questions are printed in 
terminal. File paths to input images are hardcoded, replace "IMG\_0862.png" with "IMG\_0861.jpeg" on Line 70 of \emph{hw5.m} if you get errors.

\begin{enumerate}

    \item[Part-A.]
    \ \\
    The world and image coordinates from \emph{hw4} were read into matlab and inverted using the homogenous least squares method to get the camera 
    matrix \textbf{M}. The inverted camera matrix (round to 3s.f)
    \[
    M = 
    \begin{bmatrix}
    0.03 & 0.05 & -0.14 & 0.49 \\
    -0.14 & 0.05 & -0.02 & 0.85 \\
    -0.00 & -0.00 & -0.00 & 0.0009
    \end{bmatrix}
    \]

    The vizualization comparing the projected and original image coordinates is shown in \autoref{fig:Figure1}.\\
    The resulting \textbf{RMS error} between the projected points from "M" versus the original image coordinates was \textbf{9.58}. This is lower than 
    the 17.01 and 41.28 RMS values that were obtained with camera matrix 1 and 2 in \emph{hw4}.  
    
    The calibration process does \textbf{not} minimize the sum of the squared errors(i.e., the sum of squared differences between observed and projected 
    points in the image plane). Homogeneous least squares minimizes an \textbf{algebraic error} in a linear system, not the reprojection error in image pixels. 
    $$P \cdot m = 0$$
    where $m$ represents the flattened camera matrix $P$. The solution to this minimizes the error in a linear sense (in terms of matrix $P$), which 
    corresponds to the smallest singular value of the matrix in the SVD decomposition. The projection from 3D to 2D is nonlinear, and the algebraic error 
    doesn't account for this transformation. While homogeneous least squares is computationally efficient and useful for getting an initial estimate of 
    the camera matrix, it is less than ideal for achieving accurate 2D projections. An ideal approach refines the initial matrix by minimizing reprojection 
    error through nonlinear optimization.

    \begin{figure}[H]
        \centering
        \includegraphics[scale=0.25]{output/f1_predicted_points_HLSQR.png}
        \caption{Visualization of projected points from "M" matrix.}
        \label{fig:Figure1}
    \end{figure}

    \FloatBarrier 

    \item[Part-B.]
    \ \\
    \begin{enumerate}
        \item[1.] Parametric equations for a sphere were used to generate 3D points at (x,y,z). The number of points were manually modified from 10 to 
        100, till there were no holes on the sphere.
        \item[2.] The camera position was assumed to be $[9, 14, 11]$.
        \item[3.] The dot products between the camera position and the outward normal vector of each point on the sphere was used to create a visibility 
        mask. Points less than zero are not visible, and were masked out.
        \item[4.] The Lambertian reflectance was calculated from the dot product between the sphere's surface normal and the normalized light direction. 
        Negative values were set to zero (self-shadow).
        \item[5.] The visible points were projected onto the 2D calibration image, using the camera matrix from \emph{Part A}. The points are shaded by 
        the lambertian reflectance values.
    \end{enumerate}
    The resulting plot of the projected sphere shaded by lambertian reflectance is shown in \autoref{fig:Figure2}. When the light source is in front of 
    the sphere, the reflectance is brightest in the increasing x-direction \autoref{fig:Figure2a}. However, when the light source is rotated behind the 
    sphere $[-30, 0, 0]$, the reflectance is highest in the decreasing x-direction facing the source \autoref{fig:Figure2b}. Considering that the reflectance 
    tracks with the light source, the resulting image makes sense.

    \begin{figure}[!ht]\centering
        % \hspace*{-1.2in}
        \begin{subfigure}{0.6\textwidth}
            \includegraphics[scale=0.23]{output/f2_projected_sphere_with_visible_points.png}
            \caption{Projected sphere with original light source at $[33, 29, 44]$.}
            \label{fig:Figure2a}
        \end{subfigure}
    \vfil
        % \hspace*{-1.2in}
        \begin{subfigure}{0.6\textwidth}
        \includegraphics[scale=0.23]{output/f3_projected_sphere_with_rotated_light.png}
        \caption{Projected sphere with rotated light source at $[-30, 0, 0]$}
        \label{fig:Figure2b}
        \end{subfigure}
        \caption{Projected sphere at world coordinates $[3,2,3]$ using camera matrix from \emph{Part A}, 
        showing the effect of varying light sources. World coordinates are in inches.}
        \label{fig:Figure2}
    \end{figure}

    \FloatBarrier 

    \item[Part-C.]
    \ \\
    \begin{enumerate}
    \item[1.]
    \ \\
    The camera matrix \( M \) can be decomposed into three matrices, and is generally expressed as:
    $$
    M = K \cdot [R | t]
    $$
    Where:\\
    - \( K \) is the \textbf{intrinsic parameter matrix}.\\
    - \( R \) is the \textbf{rotation matrix} that describes the orientation of the camera.\\
    - \( t \) is the \textbf{translation vector} that describes the position of the camera.
    
    The intrisic parameter matrix \( K \) is dependent on \textit{Translation}, \textit{Scaling}, and \textit{Shear} matrices.
    $$
    K = 
    \underbrace{\begin{bmatrix}
    1 & 0 & u_0 \\
    0 & 1 & v_0 \\
    0 & 0 & 1
    \end{bmatrix}}_{\text{2D Translation}} \times 
    \underbrace{\begin{bmatrix}
    \alpha & 0 & 0 \\
    0 & \beta & 0 \\
    0 & 0 & 1
    \end{bmatrix}}_{\text{2D Scaling}} \times 
    \underbrace{\begin{bmatrix}
    1 & \gamma & 0 \\
    0 & 1 & 0 \\
    0 & 0 & 1
    \end{bmatrix}}_{\text{2D Shear}}
    $$
    where:\\
    - \( \alpha \): The \textbf{horizontal scaling factor} (focal length (pixels) along the x-axis).\\
    - \( \beta \): The \textbf{vertical scaling factor} (focal length (pixels) along the y-axis).\\
    - \( \gamma \): The \textbf{skew} between the x and y axes.\\
    - \( u_0, v_0 \): The coordinates of the \textbf{principal point} which is the intersection of the camera's optical axis with the image plane. These values correspond 
    to the pixel coordinates where the optical center of the camera is located.\\

    We assume that the camera axes are perpendicular (skew angle = 90 degrees), so we can ignore skew, reducing the number of unknowns from 11 to 10. The matrix 
    \( K \) is a \( 3 \times 3 \) upper triangular matrix that describes how the camera's internal parameters map 3D points into 2D image coordinates. \( K \) can 
    be written as
    $$
    K = \begin{bmatrix}
    \alpha & \gamma & u_0 \\
    0      & \beta  & v_0 \\
    0      & 0      & 1
    \end{bmatrix} = 
    \begin{bmatrix}
    \alpha & 0      & u_0 \\
    0      & \beta  & v_0 \\
    0      & 0      & 1
    \end{bmatrix}
    $$


    
    \item[2.]
    \ \\
    From the general camera matrix expression the extrinsic matrix $X$ can be written as $X = [R | t]$ \\
    Where:\\
    - \( R \) is the  3 x 3 \textbf{rotation matrix} (orientation of the camera in 3D space).\\
    - \( t \) is the  3 x 1 \textbf{translation vector} (camera's position in the world coordinate system).\\

    The rotation matrix \( R \) is composed of three orthonormal rotation vectors \( \mathbf{r_1} \), \( \mathbf{r_2} \), and \( \mathbf{r_3} \), that describes the camera's 
    orientation along one of its axes (usually corresponding to the x, y, and z axes in the camera coordinate system). It has a general form of 
    $$
    R = \begin{bmatrix}
    \mathbf{r_1} & \mathbf{r_2} & \mathbf{r_3}
    \end{bmatrix}
    =
    \begin{bmatrix}
    r_{11} & r_{12} & r_{13} \\
    r_{21} & r_{22} & r_{23} \\
    r_{31} & r_{32} & r_{33}
    \end{bmatrix}
    $$
    where each vector is orthonormal, and can be defined as : \\
    - \( \mathbf{r_1} = (r_{11}, r_{21}, r_{31})^\top \) is the first orthonormal vector (x-axis rotation). \\
    - \( \mathbf{r_2} = (r_{12}, r_{22}, r_{32})^\top \) is the second orthonormal vector (y-axis rotation). \\
    - \( \mathbf{r_3} = (r_{13}, r_{23}, r_{33})^\top \) is the third orthonormal vector (z-axis rotation). \\

    If the camera is located at \( (t_x, t_y, t_z) \), the translation vector is:
    $$
    t = \begin{bmatrix}
    t_x \\
    t_y \\
    t_z
    \end{bmatrix}
    $$

    We can combine the rotation matrix \( R \) and translation vector \( t \) to form a rigid matrix \( X \) that is defined by three orthonormal rotation vectors and a 
    translation vector:

    $$
    X = [R | t]
    =
    \left[\begin{array}{ccc|c}
    r_{11} & r_{12} & r_{13} & t_x \\
    r_{21} & r_{22} & r_{23} & t_y \\
    r_{31} & r_{32} & r_{33} & t_z
    \end{array} \right]
    $$
    
    \item[3.]
    \ \\
    The multiplication of $K$ and $X$ from Part C1 and C2 gives
    $$
    M = \begin{bmatrix}
    \alpha & 0 & u_0 \\
    0 & \beta & v_0 \\
    0 & 0 & 1
    \end{bmatrix}
    \cdot
    \begin{bmatrix}
    r_{11} & r_{12} & r_{13} & t_x \\
    r_{21} & r_{22} & r_{23} & t_y \\
    r_{31} & r_{32} & r_{33} & t_z
    \end{bmatrix}
    $$

    The multiplication of $K$ rows with $X$ columns can be written as 
    $$
    M_1 = 
    \begin{bmatrix}
    \alpha & 0 & u_0
    \end{bmatrix}
    \cdot
    \begin{bmatrix}
    r_{11} & r_{12} & r_{13} & t_x \\
    r_{21} & r_{22} & r_{23} & t_y \\
    r_{31} & r_{32} & r_{33} & t_z
    \end{bmatrix}
    =
    \begin{bmatrix}
    \alpha r_{11} + u_0 r_{31} & \alpha r_{12} + u_0 r_{32} & \alpha r_{13} + u_0 r_{33} & \alpha t_x + u_0 t_z
    \end{bmatrix}
    $$
    $$
    M_2 = 
    \begin{bmatrix}
    0 & \beta & v_0
    \end{bmatrix}
    \cdot
    \begin{bmatrix}
    r_{11} & r_{12} & r_{13} & t_x \\
    r_{21} & r_{22} & r_{23} & t_y \\
    r_{31} & r_{32} & r_{33} & t_z
    \end{bmatrix}
    =
    \begin{bmatrix}
    \beta r_{21} + v_0 r_{31} & \beta r_{22} + v_0 r_{32} & \beta r_{23} + v_0 r_{33} & \beta t_y + v_0 t_z
    \end{bmatrix}
    $$
    $$
    M_3 = 
    \begin{bmatrix}
    0 & 0 & 1
    \end{bmatrix}
    \cdot
    \begin{bmatrix}
    r_{11} & r_{12} & r_{13} & t_x \\
    r_{21} & r_{22} & r_{23} & t_y \\
    r_{31} & r_{32} & r_{33} & t_z
    \end{bmatrix}
    =
    \begin{bmatrix}
    r_{31} & r_{32} & r_{33} & t_z
    \end{bmatrix}
    $$
    where $(M_1,M_2,M_3)$ are row vectors, and the final algebraic form of $M$ is 
    $$
    M = \begin{bmatrix}
    \alpha r_{11} + u_0 r_{31} & \alpha r_{12} + u_0 r_{32} & \alpha r_{13} + u_0 r_{33} & \alpha t_x + u_0 t_z \\
    \beta r_{21} + v_0 r_{31} & \beta r_{22} + v_0 r_{32} & \beta r_{23} + v_0 r_{33} & \beta t_y + v_0 t_z \\
    r_{31} & r_{32} & r_{33} & t_z
    \end{bmatrix}
    $$
    
    \item[4.]
    \ \\
    Considering the $M$ value that was obtained by optimization in Part A,
    $$
    M = 
    \begin{bmatrix}
    \alpha r_{11} + u_0 r_{31} & \alpha r_{12} + u_0 r_{32} & \alpha r_{13} + u_0 r_{33} & \alpha t_x + u_0 t_z \\
    \beta r_{21} + v_0 r_{31} & \beta r_{22} + v_0 r_{32} & \beta r_{23} + v_0 r_{33} & \beta t_y + v_0 t_z \\
    r_{31} & r_{32} & r_{33} & t_z
    \end{bmatrix} = 
    \begin{bmatrix}
    m_{11} & m_{12} & m_{13} & m_{14} \\
    m_{21} & m_{22} & m_{23} & m_{24} \\
    m_{31} & m_{32} & m_{33} & m_{34}
    \end{bmatrix}
    $$

    If we set the problem up as camera matrix  \( \mathbf{M} = \rho M_{obs} = \rho (A \  b) \), \\
    where: \\
    - $\rho$ is the arbitrary scale factor \\
    - $A$ is a 3 x 3 matrix \\
    - $b$ is a 3 x 1 matrix \\
    $$
    M = \rho
    \begin{bmatrix}
    m_{11} & m_{12} & m_{13} & m_{14} \\
    m_{21} & m_{22} & m_{23} & m_{24} \\
    m_{31} & m_{32} & m_{33} & m_{34}
    \end{bmatrix}
    $$
    Using the \textbf{M} obtained in Part A,
    $$
    M = \begin{bmatrix}
    0.03 & 0.05 & -0.14 & 0.49 \\
    -0.14 & 0.05 & -0.02 & 0.85 \\
    -0.00 & -0.00 & -0.00 & 0.0009
    \end{bmatrix}
    $$
    $\rho$ can be derived using $\rho = \sqrt(m_{31}^2 + m_{32}^2 + m_{33}^2)$. The resulting value can be used to normalize \textbf{M} where $M = \frac{\mathbf{M}}{\rho}$. \\
    Next we consider the coefficient of $t_z = m_{34} = 0.009$. Since $t_z > 0$, we can determine that the origin of the world reference is in front. \\
    Our rotational vectors $\mathbf{r_{3i}}$ can be resolved from the M matrix directly using 
    $$r_{3i} = \rho m_{3i}, \text{where } i=1,2,3$$
    If we let our \textbf{A} matrix be represented as a series of row vectors
    \begin{equation}
    \begin{split}
    q_1 = \begin{bmatrix}m_{11} & m_{12} & m_{13}\end{bmatrix} \\
    q_2 = \begin{bmatrix}m_{21} & m_{22} & m_{23}\end{bmatrix} \\
    q_3 = \begin{bmatrix}m_{31} & m_{32} & m_{33}\end{bmatrix}
    \end{split}
    \end{equation}
    We can rewrite our unknowns in terms of the row vectors to derive the image origin coordinates 
    \setlength{\mathindent}{0pt}
    \begin{align*}
    q_1^T q_3 & = m_{11}m_{31} + m_{12}m_{32} + m_{13}m_{33} & \\
    & = m_{11}m_{31} + m_{12}m_{32} + m_{13}m_{33} &= (\alpha r_{11} + u_0 r_{31} \  \alpha r_{12} + u_0 r_{32} \  \alpha r_{13} + u_0 r_{33}) \\
    && = (\alpha r_{11} \ \alpha r_{12} \ \alpha r_{13})\cdot(r_{31}  \ r_{32}  \ r_{33}) +  \\ 
    && (u_0 r_{31}  \ u_0 r_{32} \ u_0 r_{33})\cdot(r_{31}  \ r_{32}  \ r_{33}) \\
    && = (u_0 r_{31}  \ u_0 r_{32} \ u_0 r_{33})\cdot(r_{31}  \ r_{32}  \ r_{33}) \\
    && = (u_0 r_{31}^2  \ u_0 r_{32}^2 \ u_0 r_{33}^2) \\
    && = u_0 (r_{31}^2  \ r_{32}^2 \ r_{33}^2) \\
    q_1^T q_3 & = \mathbf{u_0} \\
    u_0 & = q_1^T q_3 \\
    \therefore v_0 & = q_2^T q_3
    \end{align*}
    The horizontal and vertical focal lengths can also be derived from 
    \begin{align*}
    q_1^T q_1 & = m_{11}m_{11} + m_{12}m_{12} + m_{13}m_{13} & {}  \\
    & = m_{11}m_{11} + m_{12}m_{12} + m_{13}m_{13} &= (\alpha r_{11} + u_0 r_{31} \  \alpha r_{12} + u_0 r_{32} \  \alpha r_{13} + u_0 r_{33}) & {} \\
    & {} & \cdot  (\alpha r_{11} + u_0 r_{31} \  \alpha r_{12} + u_0 r_{32} \  \alpha r_{13} + u_0 r_{33})  & {}  \\
    & {} & = (\alpha r_{11} + u_0 r_{31})^2 + (\alpha r_{12} + u_0 r_{32})^2 + (\alpha r_{13} + u_0 r_{32})^2  & {}  \\
    & {} & = (\alpha^2 r_{11}^2 + u_0^2 r_{31}^2) + (\alpha^2 r_{12}^2 + u_0^2 r_{32}^2) + (\alpha^2 r_{13}^2 + u_0^2 r_{32}^2) & {} \\
    q_1^T q_1 & = \mathbf{\alpha^2 + u_0^2} \\
    \alpha & = \sqrt{q_1^T q_1 - u_0^2} \\
    \therefore \beta & = \sqrt{q_2^T q_2 - v_0^2} 
    \end{align*}

    The parameters for the \textbf{extrinsic matrix} can also be derived
    \begin{align*}
    u_0 r_{31} + \alpha r_{11} - r_{31} u_0 & = \rho (u_0 m_{31} - m_{11}), \\
    r_{11} & = \frac {\rho (u_0 m_{31} - m_{11})}{\alpha}, & {}\\
    r_{1i} & = \frac {\rho (u_0 m_{3i} - m_{1i})}{\alpha}, & \text{i = 1,2,3}\\
    r_{2i} & = \frac {\rho (v_0 m_{3i} - m_{2i})}{\beta}, & \text{i = 1,2,3}\\
    t_{x} & = \frac {\rho (u_0 m_{34} - m_{14})}{\alpha}, & {}\\
    t_{y} & = \frac {\rho (v_0 m_{34} - m_{24})}{\beta}, & {}\\
    \end{align*}

    The resulting values from the calculations are documented in \autoref{tab:Table1}.
    \begin{table}[h!]
    \begin{center}
    \begin{tabular}{ ||c | c|| } 
        \hline
        Parameter & Result \\ 
        \hline \hline
        $\alpha$ & 3160 \\ 
        $\beta$  & 3031 \\ 
        $(u_0,v_0)$ & (537,1024) \\ 
        Camera location & [9.03, 13.7, 10.9] \\ 
        Camera orientation & [0.49, 0.67, 0.56] \\
        \hline
    \end{tabular}
    \caption{Estimates of unknown values derived from the algebraic solution to the camera matrix.}
    \label{tab:Table1}
    \end{center}
    \end{table}
    The resulting intrinsic matrix $\mathbf{K}$ was 
    $$
    K = \begin{bmatrix}
    3160 & 0 & 537 \\
        0 & 3031 & 1024 \\
        0 & 0 & 1.0
    \end{bmatrix}
    $$
    and the extrinsic matrix $\mathbf{X}$ was
    $$
    X = \begin{bmatrix}
    0.29 & 0.48 & -0.83 & 0.09 \\
    -0.90 & 0.47 & -0.07 & 0.72 \\
    0.49 & 0.67 & 0.56 & 19.9
    \end{bmatrix}
    $$

    The values of $\alpha$ and $\beta$ were also estimated directly from "IMG\_0859" using the transformations
    \begin{align*}
    & \alpha = \frac{D \times p_h}{d_h}  &  \beta = \frac{D \times p_v}{d_v}
    \end{align*}
    where \\
    - \textbf{D} is the distance to measured surface (11.5 inches). \\ 
    - $d_v$ is the vertical distance of imaged point (4 inches). \\ 
    - $p_v$ is the vertical distance from the center of the camera in pixels (1200 pixels). \\
    - $d_h$ is the horizontal distance of imaged point (6 inches) \\ 
    - $p_h$ is the horizontal distance from the center of the camera in pixels (1600 pixels). \\

    The resulting values of $\alpha$ and $\beta$ were \emph{3067} and \emph{3450} respectively. The values are similar to those obtained with the intrinsic matrix 
    with the exception that there appears to be a coordinate switch which I couldn't resolve with the hints or videos.

    \end{enumerate}
    





    % if we set the problem up as camera matrix  \( \mathbf{M} = \rho M_{obs} = \rho (A \  b) \), \\
    % where: \\
    % - $\rho$ is the arbitrary scale factor \\
    % - $A$ is a 3 x 3 matrix \\
    % - $b$ is a 3 x 1 matrix \\

    % \begin{equation}
    % \tag{C.4.1}
    % B = \rho A
    % \end{equation}
    % \begin{equation}
    % \tag{C.4.2}
    % c = \rho b
    % \end{equation}

    % From (C.4.1), we can estimate intrinsic matrix \textbf{K}
    % \[
    % \centering
    % K\equiv BB^{T}=\rho\rho^{T}=
    % \begin{bmatrix}
    % \underbrace{\alpha^{2}+\gamma^{2}+u_{0}^{2}}_{k_u} & \underbrace{u_{0}v_{0}+c \beta}_{k_c} & u_{0} \\ 
    % \underbrace{u_{0}v_{0}+c \alpha}_{k_c} & \underbrace{\alpha^{2}+v_{0}^{2}}_{k_v} & v_{0} \\ 
    % u_{0} & v_{0} & 1
    % \end{bmatrix}
    % \]

    % Because \textbf{M} is defined up to a scale factor, the last element of \(K=BB^{T}\) is usually not equal to 1, so we have to normalize it such that \(K_{33}\) (the last 
    % element) = 1. After that, we can solve for the unknown intrinsic matrix parameters (gamma is ignored)
    % \begin{equation}
    % \tag{C.4.3}
    % u_{0}=K_{13}
    % \end{equation}  
    % \begin{equation}
    % \tag{C.4.4}
    % v_{0}=K_{23}
    % \end{equation}        
    % \begin{equation}
    % \tag{C.4.5}
    % \alpha=\sqrt{k_{u}-u_{0}^{2}-\gamma^{2}}
    % \end{equation}
    % \begin{equation}
    % \tag{C.4.6}
    % \beta=\sqrt{k_{v}-v_{0}^{2}}
    % \end{equation}

    % Recovering the camera center, \emph{C}, is straightforward. Note that the last column of \textbf{M} is \(-\rho b \), the camera position can be derived by 
    % left-multiplying \(-B^{-1} \times b \)

    % In matlab, this gives 
    % \begin{lstlisting}[language=Matlab]
    % B = M(:, 1:3);
    % c = M(:, 4);
    % % Compute and Normalize K
    % K = B * B';  
    % K = K / K(3, 3);

    % % Extract elements from K
    % k_u = K(1, 1);
    % k_c = K(1, 2);
    % k_v = K(2, 2);

    % % Compute intrinsic parameters
    % u0 = K(1, 3);
    % v0 = K(2, 3);
    % alpha = sqrt(k_u - u0^2);
    % beta = sqrt(k_v - v0^2); % gamma is zero

    % % Estimate the camera location
    % C = -inv(B) * b; %
    % \end{lstlisting}

    % Once the camera projection matrix P is known, we can uniquely recover the intrinsic and extrinsic parameters of the camera. Let us denote the first \(3\times3\) 
    % submatrix of P by B and the last column of P by b, i.e., \(P\equiv[\begin{matrix}B&b\end{matrix}]\) Since \(P=A[\begin{matrix}R&t\end{matrix}],\) we have

    % \begin{equation}
    % \tag{2.5}
    % B=AR
    % \end{equation}
    % \begin{equation}
    % \tag{2.6}
    % b=At
    % \end{equation}

    % From (2.5), we have
    % \[
    % K\equiv BB^{T}=AA^{T}=
    % \begin{bmatrix}
    % \underbrace{\alpha^{2}+\gamma^{2}+u_{0}^{2}}_{k_u} & \underbrace{u_{0}v_{0}+c \beta}_{k_c} & u_{0} \\ 
    % \underbrace{u_{0}v_{0}+c \alpha}_{k_c} & \underbrace{\alpha^{2}+v_{0}^{2}}_{k_v} & v_{0} \\ 
    % u_{0} & v_{0} & 1
    % \end{bmatrix}
    % \]

    % Because P is defined up to a scale factor, the last element of \(K=BB^{T}\) is usually not equal to 1, so we have to normalize it such that \(K_{33}(\) the last element) = 1. 
    % After that, we immediately obtain

    % \begin{equation}
    % \tag{2.7}
    % u_{0}=K_{13}
    % \end{equation}  
    % \begin{equation}
    % \tag{2.8}
    % v_{0}=K_{23}
    % \end{equation}      
    % \begin{equation}
    % \tag{2.9}
    % \beta=\sqrt{k_{v}-v_{0}^{2}}
    % \end{equation}        
    % \begin{equation}
    % \tag{2.10}
    % \gamma=\frac{k_{c}-u_{0}v_{0}}{\beta}
    % \end{equation}     
    % \begin{equation}
    % \tag{2.11}
    % \alpha=\sqrt{k_{u}-u_{0}^{2}-\gamma^{2}}
    % \end{equation}

    % The solution is unambiguous because: \(\alpha>0\) and \(\beta>0.\)
    % Once the intrinsic parameters, or equivalently matrix A, are known, the extrinsic parameters can be determined from (2.5) and (2.6) as:
    % \begin{equation}
    % \tag{2.12}
    % R=A^{-1}B
    % \end{equation}
    % \begin{equation}
    % \tag{2.13}
    % t=A^{-1}b
    % \end{equation}

\end{enumerate}

\end{document}