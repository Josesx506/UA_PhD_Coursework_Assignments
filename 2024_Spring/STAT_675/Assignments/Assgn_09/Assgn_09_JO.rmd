---
title: "Assignment_09_JO"
subtitle: "Markov Chain Monte Carlo Methods."
output:
  pdf_document: default
header-includes:
  - \usepackage{amsmath}
---

```{r}
set.seed(675)
library(dplyr)
library(ggplot2)
library(gridExtra)
```
Please answer the following questions and submit both R codes and the results. Make all results repro- ducible.

1. Generate $N(0,1)$ using random walk Metropolis algorithm based on proposal distribution 
    $g(x|x^{(t)}) \sim U(x^{(t)} - a, x^{(t)} + a)$. Generate Markov chains with length 20,000 using 
    $a = 0.1,\ 1\ and\ 10$, respectively. Compare the means, variances and distributions.
```{r}
# Generate N(0,1) samples using random walk Metropolis algorithm
metropolis_sampler <- function(proposal_scale, num_samples) {
  # Initialize variables
  x <- numeric(num_samples)
  x[1] <- rnorm(1)  # Initial value

  # Target distribution (standard normal)
  target_pdf <- function(x) exp(-0.5*x^2) / sqrt(2*pi)

  # Metropolis algorithm
  for (t in 2:num_samples) {
    # Generate candidate from proposal distribution
    y <- runif(1, x[t - 1] - proposal_scale, x[t - 1] + proposal_scale)

    # Compute acceptance probability
    alpha <- target_pdf(y) / target_pdf(x[t-1])

    # Accept or reject the candidate
    if (runif(1) < min(1, alpha)) {
      x[t] <- y
    } else {
      x[t] <- x[t - 1]
    }
  }

  return(x)
}

# Parameters
proposal_scales <- c(0.1, 1, 10)
num_samples <- 20000

# Generate samples for each proposal scale
samples <- lapply(proposal_scales, function(scale) {
  metropolis_sampler(scale, num_samples)
})

# Calculate means and variances
means <- sapply(samples, mean)
variances <- sapply(samples, var)

# Plot histograms
par(mfrow = c(1, length(proposal_scales)), mar=c(4, 4, 2, 1))
for (i in 1:length(proposal_scales)) {
  hist(samples[[i]], breaks = 50,
       main = paste("Proposal Scale =", proposal_scales[i],
                    "\nMean =", round(means[i], 4), ", Variance =",
                    round(variances[i], 4)),
       xlab = "Value", prob = TRUE, col = "lightblue", border = "white")
}

# Create a data frame for mean and variance comparison
results <- data.frame(Proposal_Scale = proposal_scales,
                      Mean = means, Variance = variances)
print(results)
```

2. Use independent sampler method (Independent Metropolis-Hastings Algorithm) to solve Example 9.5 in the 
  textbook (Statistical Computing with R page 256, available from UA library web). Use a flat 
  prior $U(0,0.5)$ for $\beta$. Use the same data as in the text book, i.e., (82, 72, 45, 34, 17), 
  so the results are comparable.
```{r}
# Function to calculate the likelihood
# Parameters
m <- 5000  # Length of the chain
burn <- 1000  # Burn-in time
win <- c(82, 72, 45, 34, 17)  # Observed frequencies of winners
num_samples <- m + burn  # Total number of samples

# Define the target density function (without the constant)
prob <- function(beta, win) {
  if (beta < 0 || beta >= 0.5) {
    return(0)
  }
  return((1 / 3)^win[1] *
           ((1 - beta) / 3)^win[2] *
           ((1 - 2 * beta) / 3)^win[3] *
           ((2 * beta) / 3)^win[4] * (beta / 3)^win[5])
}

# Independent Metropolis-Hastings Algorithm
beta <- numeric(m)           # the chain
beta[1] <- runif(1, 0, 0.5)  # initial value for beta
for (i in 2:m) {
  # Proposal distribution: Uniform(0, 0.5)
  beta_proposed <- runif(1, 0, 0.5)

  # Acceptance probability
  alpha <- prob(beta_proposed, win) / prob(beta[i - 1], win)

  # Accept or reject the proposal
  if (runif(1) < alpha) {
    beta[i] <- beta_proposed
  } else {
    beta[i] <- beta[i - 1]
  }
}

# Burn-in period
beta_burn <- beta[(burn + 1):m]

# Print the mean of the posterior samples for beta
print(paste("The mean is", round(mean(beta_burn), 5)))



# Combine chain and histogram data into a data frame
data <- data.frame(Iteration = seq_along(beta_burn),
                   Beta = beta_burn)

# Line plot of the chain
line_plot <- ggplot(data, aes(x = Iteration, y = Beta)) +
  geom_line(color = "blue") +
  labs(x = "Iteration", y = "x") +
  theme_minimal()

# Histogram distribution of beta
histogram_plot <- ggplot(data, aes(x = Beta)) +
  geom_histogram(binwidth = 0.01, fill = "lightblue", color = "black") +
  labs(x = expression(beta), y = "x") + theme_minimal()

# Combine plots
combined_plot <- grid.arrange(line_plot, histogram_plot, ncol = 1)
```

3. Textbook Exercise 9.6. Rao [220, Sec. 5g] presented an example on genetic linkage of 197 animals
    in four categories. The group sizes are (125, 18, 20, 34). Assume that the probabilities of the 
    corresponding multinomial distribution are $(frac {1} {2} + frac {\theta} {4}, 
    frac {1 - \theta} {4}, frac {1 - \theta} {4}, frac {\theta} {4})$
    Estimate the posterior distribution of $\theta$ given the observed sample, using the Random-walk
    Metropolis sampler.
```{r}
# Define the observed sample
observed_counts <- c(125, 18, 20, 34)
total_animals <- sum(observed_counts)

# Function to calculate the likelihood
likelihood <- function(theta, observed_counts) {
  multinomial_prob <- c(0.5 + theta / 4,
                        (1 - theta) / 4,
                        (1 - theta) / 4,
                        theta / 4)
  return(prod(dmultinom(observed_counts,
                        size = total_animals,
                        prob = multinomial_prob)))
}

# Function to calculate the prior
prior <- function(theta) {
  if (theta >= 0 && theta <= 1) {
    return(1)  # Flat prior U(0, 1)
  } else {
    return(0)
  }
}

# Function to calculate the posterior
posterior <- function(theta, observed_counts) {
  likelihood_val <- likelihood(theta, observed_counts)
  prior_val <- prior(theta)
  return(likelihood_val * prior_val)
}

# Random-walk Metropolis sampler
metropolis_sampler <- function(num_samples, theta_initial,
                               observed_counts, proposal_sd) {
  theta <- numeric(num_samples)
  theta[1] <- theta_initial  # Initial value

  for (t in 2:num_samples) {
    # Propose a new theta from a normal distribution centered at the current value
    theta_proposed <- rnorm(1, theta[t-1], proposal_sd)

    # Calculate acceptance ratio
    alpha <- posterior(theta_proposed, observed_counts) /
      posterior(theta[t - 1], observed_counts)

    # Accept or reject the proposal
    if (runif(1) < min(1, alpha)) {
      theta[t] <- theta_proposed
    } else {
      theta[t] <- theta[t - 1]
    }
  }

  return(theta)
}

# Parameters
num_samples <- 10000
theta_initial <- 0.5  # Initial value for theta
proposal_sd <- 0.05  # Standard deviation of the proposal distribution

# Run Random-walk Metropolis sampler
theta_samples <- metropolis_sampler(num_samples, theta_initial,
                                    observed_counts, proposal_sd)

# Print the mean of the posterior samples for beta
print(paste("The mean is", round(mean(theta_samples), 5)))


# Create data frame for plotting
data <- data.frame(iteration = seq_along(theta_samples),
                   theta = theta_samples)

# Line plot of the chain
line_plot <- ggplot(data, aes(x = iteration, y = theta)) +
  geom_line(color = "blue") +
  labs(x = "Iteration", y = "x") +
  theme_minimal()

# Histogram distribution of theta
histogram_plot <- ggplot(data, aes(x = theta)) +
  geom_histogram(binwidth = 0.01, fill = "lightblue", color = "black") +
  labs(x = expression(theta), y = "Frequency") + theme_minimal()

# Combine plots
combined_plot <- grid.arrange(line_plot, histogram_plot, ncol = 1)
```

4.  Textbook Exercise 9.8. (Compare the empirical marginal distributions with the theoretical ones.).
```{r}
```